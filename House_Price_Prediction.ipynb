{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1.Import Libraries","metadata":{"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm\nimport missingno as mno\nsns.set_style(\"whitegrid\", {\"grid.color\": \".2\", \"grid.linestyle\": \":\"})\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nfrom sklearn.linear_model import Ridge, Lasso, ElasticNet\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","metadata":{"id":"4DTkZ-uhePeQ","tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:30.563172Z","iopub.execute_input":"2023-08-04T11:37:30.563646Z","iopub.status.idle":"2023-08-04T11:37:30.572985Z","shell.execute_reply.started":"2023-08-04T11:37:30.563610Z","shell.execute_reply":"2023-08-04T11:37:30.571708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:30.575113Z","iopub.execute_input":"2023-08-04T11:37:30.575484Z","iopub.status.idle":"2023-08-04T11:37:30.588807Z","shell.execute_reply.started":"2023-08-04T11:37:30.575452Z","shell.execute_reply":"2023-08-04T11:37:30.587799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Load and Show Basic Data Info","metadata":{"tags":[]}},{"cell_type":"code","source":"#Get dataset directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:30.590570Z","iopub.execute_input":"2023-08-04T11:37:30.591265Z","iopub.status.idle":"2023-08-04T11:37:30.610878Z","shell.execute_reply.started":"2023-08-04T11:37:30.591218Z","shell.execute_reply":"2023-08-04T11:37:30.609736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data\nhousing = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ndata = housing.copy()\n\n#show all columns & rows\npd.set_option('display.max_columns', None)  \npd.set_option('display.max_rows', None)  \n\n# Show the first 5 rows\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:30.614500Z","iopub.execute_input":"2023-08-04T11:37:30.614980Z","iopub.status.idle":"2023-08-04T11:37:30.700126Z","shell.execute_reply.started":"2023-08-04T11:37:30.614935Z","shell.execute_reply":"2023-08-04T11:37:30.698882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This dataset contains 81 columns. The first column is the ID, and the last column is our target variable'SalePrice.' The remaining columns are potential features that we need to analyze further to determine which ones might be helpful in predicting 'SalePrice.'","metadata":{}},{"cell_type":"code","source":"# Show the basic information of the data\ndata.info()","metadata":{"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:30.701743Z","iopub.execute_input":"2023-08-04T11:37:30.702094Z","iopub.status.idle":"2023-08-04T11:37:30.741024Z","shell.execute_reply.started":"2023-08-04T11:37:30.702063Z","shell.execute_reply":"2023-08-04T11:37:30.739919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This dataset consists of 1,460 samplesï¼Œand contains 43 features of object type (typically strings or categories), 35 features of integer type, and 3 features of float type.","metadata":{}},{"cell_type":"markdown","source":"# 3.Exploratory Data Analysis","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## 3.1.Target Distribution","metadata":{"tags":[]}},{"cell_type":"code","source":"# Plot the distribution of 'LotFrontage' values\nplt.figure(figsize=(7, 3))\nsns.distplot(data['SalePrice'],fit = norm)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:30.742222Z","iopub.execute_input":"2023-08-04T11:37:30.742539Z","iopub.status.idle":"2023-08-04T11:37:31.116450Z","shell.execute_reply.started":"2023-08-04T11:37:30.742511Z","shell.execute_reply":"2023-08-04T11:37:31.115359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of target appears to be right-skewed, meaning that most houses have saleprices concentrated in a smaller range, while larger values are less common. ","metadata":{}},{"cell_type":"markdown","source":"## 3.2.Correlation Matrix","metadata":{"tags":[]}},{"cell_type":"code","source":"# Compute the correlation matrix\ncorr_matrix = data.corr()\n\n# Set up the matplotlib figure\nplt.figure(figsize=(12, 9))\n\n# Draw the heatmap\nsns.heatmap(corr_matrix, vmax=.8, square=True, cmap='coolwarm')\nplt.show()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:31.117853Z","iopub.execute_input":"2023-08-04T11:37:31.118205Z","iopub.status.idle":"2023-08-04T11:37:32.379210Z","shell.execute_reply.started":"2023-08-04T11:37:31.118174Z","shell.execute_reply":"2023-08-04T11:37:32.377886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix['SalePrice'].sort_values(ascending=False)","metadata":{"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:32.380995Z","iopub.execute_input":"2023-08-04T11:37:32.381693Z","iopub.status.idle":"2023-08-04T11:37:32.394332Z","shell.execute_reply.started":"2023-08-04T11:37:32.381616Z","shell.execute_reply":"2023-08-04T11:37:32.393201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.1.Features with high corr to target","metadata":{"tags":[]}},{"cell_type":"code","source":"corr_matrix = data.corr()\n\n#Set high correlation threshold\nthres = 0.5\n\n# Find features that have a correlation with 'SalePrice' greater than 0.5\nhigh_corr_cols = corr_matrix[abs(corr_matrix['SalePrice']) > thres].index.tolist()\nhigh_corr_features = [col for col in high_corr_cols if (col != 'SalePrice')]\n\nprint('Features with high correlations to target are:')\nprint(high_corr_features)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:32.398229Z","iopub.execute_input":"2023-08-04T11:37:32.398577Z","iopub.status.idle":"2023-08-04T11:37:32.413804Z","shell.execute_reply.started":"2023-08-04T11:37:32.398547Z","shell.execute_reply":"2023-08-04T11:37:32.412605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize Features with high correlation to target","metadata":{"tags":[]}},{"cell_type":"code","source":"#Visualize Correlation \nplt.figure(figsize=(10,10))\ng = sns.heatmap(data[high_corr_cols].corr(),annot=True,cmap=\"RdYlGn\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:32.415679Z","iopub.execute_input":"2023-08-04T11:37:32.416955Z","iopub.status.idle":"2023-08-04T11:37:33.422816Z","shell.execute_reply.started":"2023-08-04T11:37:32.416910Z","shell.execute_reply":"2023-08-04T11:37:33.421731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.2.Features with low corr to target","metadata":{"tags":[]}},{"cell_type":"code","source":"#Set low correlation threshold\nthres = 0.1\n\n# Find features that have a correlation with 'SalePrice' greater than 0.5\nlow_corr_cols = corr_matrix[abs(corr_matrix['SalePrice']) < thres].index.tolist()\nlow_corr_features = [col for col in low_corr_cols if (col != 'SalePrice')]\n\nprint('Features with low correlations to target are:')\nprint(low_corr_features)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:33.424287Z","iopub.execute_input":"2023-08-04T11:37:33.424683Z","iopub.status.idle":"2023-08-04T11:37:33.433324Z","shell.execute_reply.started":"2023-08-04T11:37:33.424628Z","shell.execute_reply":"2023-08-04T11:37:33.431950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.Data Preprocessing","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## 4.1.Delete Useless Columns\nWe can start by removing columns that do not contribute to predicting 'SalePrice.' For example, the 'Id' column is simply an identifier for each sample and does not provide any helpful information for predicting 'SalePrice.' Therefore, we can delete it from the dataset.","metadata":{"tags":[]}},{"cell_type":"code","source":"# Drop the 'Id' column\ndata = data.drop('Id', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:33.435078Z","iopub.execute_input":"2023-08-04T11:37:33.435451Z","iopub.status.idle":"2023-08-04T11:37:33.446812Z","shell.execute_reply.started":"2023-08-04T11:37:33.435417Z","shell.execute_reply":"2023-08-04T11:37:33.445501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2.Covert Data Type\nAccording to data description, MSSubClass Identifies the type of dwelling involved in the sale. It's current dtype is float64, its values indicating types.","metadata":{"tags":[]}},{"cell_type":"code","source":"# convert to object\ndata['MSSubClass'] = data['MSSubClass'].astype('object')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:33.448726Z","iopub.execute_input":"2023-08-04T11:37:33.449521Z","iopub.status.idle":"2023-08-04T11:37:33.460557Z","shell.execute_reply.started":"2023-08-04T11:37:33.449472Z","shell.execute_reply":"2023-08-04T11:37:33.459305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3.Remove Duplicates\nWe need to check if there are any duplicate rows in the dataset. If duplicates are found, we should remove them because duplicate data can have a negative impact on our model.","metadata":{"tags":[]}},{"cell_type":"code","source":"# Check for duplicates\nduplicates = data.duplicated().sum()\n\nduplicates","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:33.462199Z","iopub.execute_input":"2023-08-04T11:37:33.462693Z","iopub.status.idle":"2023-08-04T11:37:33.495353Z","shell.execute_reply.started":"2023-08-04T11:37:33.462633Z","shell.execute_reply":"2023-08-04T11:37:33.494236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's a good news that the dataset does not have any duplicate rows. So, We don't need to handle duplicate data.","metadata":{}},{"cell_type":"markdown","source":"## 4.4.Missing Values\nLet's handle missing values by first looking at the number of missing values in each column. This can help us determine how to handle these missing values.","metadata":{"tags":[]}},{"cell_type":"markdown","source":"### 4.4.1.Missing Value Analysis","metadata":{"tags":[]}},{"cell_type":"code","source":"# Check for missing values\ntotal = data.isnull().sum().sort_values(ascending=False)\ntotal = total[total > 0]\npercent = (data.isnull().sum() / data.shape[0] * 100).round(2).sort_values(ascending=False)\npercent = percent[percent > 0] \n\ndtypes = data.dtypes[total.index]\nresult = pd.concat([total, percent, dtypes], axis=1, keys=['Total', 'Percent', 'Dtype'])\nresult","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:33.497402Z","iopub.execute_input":"2023-08-04T11:37:33.497886Z","iopub.status.idle":"2023-08-04T11:37:33.565623Z","shell.execute_reply.started":"2023-08-04T11:37:33.497842Z","shell.execute_reply":"2023-08-04T11:37:33.564424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that some features have a large number of missing values, such as 'PoolQC,' 'MiscFeature,' 'Alley,' and 'Fence.' Most of the values in these features are missing, so we can consider directly deleting these features.","metadata":{}},{"cell_type":"code","source":"#Visualizing columns with missing values\nmno.matrix(data.loc[:, data.isna().any()], color = '0.2')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:33.567431Z","iopub.execute_input":"2023-08-04T11:37:33.568173Z","iopub.status.idle":"2023-08-04T11:37:34.658473Z","shell.execute_reply.started":"2023-08-04T11:37:33.568129Z","shell.execute_reply":"2023-08-04T11:37:34.657451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like some values are not missing at random, such as 'MasVnr', 'Bsmt', and'Garage'related features","metadata":{}},{"cell_type":"markdown","source":"### 4.4.2.Treat Missing Values for Each Feature","metadata":{"tags":[]}},{"cell_type":"markdown","source":"#### 1.LotFrontage\nLinear feet of street connected to property","metadata":{"tags":[]}},{"cell_type":"markdown","source":"* Numerical feature\n* Values missing at random\n* Missing percentage: 17.74%\n\nThe distribution of 'LotFrontage' appears to be right-skewed, meaning that most houses have street frontage lengths concentrated in a smaller range, while larger values are less common. In this case, impute missing values with median may be better than using the mean, as the median is more robust to outliers and skewed distributions.","metadata":{"tags":[]}},{"cell_type":"code","source":"# Plot the distribution of 'LotFrontage' values\nplt.figure(figsize=(5, 3))\nsns.distplot(data['LotFrontage'], fit = norm)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:34.659719Z","iopub.execute_input":"2023-08-04T11:37:34.660074Z","iopub.status.idle":"2023-08-04T11:37:35.121155Z","shell.execute_reply.started":"2023-08-04T11:37:34.660043Z","shell.execute_reply":"2023-08-04T11:37:35.119748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Impute with median\ndata['LotFrontage'].fillna(data['LotFrontage'].median(), inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.122842Z","iopub.execute_input":"2023-08-04T11:37:35.123308Z","iopub.status.idle":"2023-08-04T11:37:35.131369Z","shell.execute_reply.started":"2023-08-04T11:37:35.123264Z","shell.execute_reply":"2023-08-04T11:37:35.130193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.Alley\nType of alley access to property","metadata":{"tags":[]}},{"cell_type":"markdown","source":"* Categorical feature\n* Values not missing at random\n* Mssing percentage: 93.77%\n\nMissing values indicate no alley at the property, so impute with 'None'.","metadata":{}},{"cell_type":"code","source":"#show unique values\ndata['Alley'].value_counts(dropna = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.132925Z","iopub.execute_input":"2023-08-04T11:37:35.133258Z","iopub.status.idle":"2023-08-04T11:37:35.146301Z","shell.execute_reply.started":"2023-08-04T11:37:35.133230Z","shell.execute_reply":"2023-08-04T11:37:35.145197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#impute with 'None'\ndata['Alley'].fillna('None', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.150820Z","iopub.execute_input":"2023-08-04T11:37:35.151225Z","iopub.status.idle":"2023-08-04T11:37:35.158798Z","shell.execute_reply.started":"2023-08-04T11:37:35.151191Z","shell.execute_reply":"2023-08-04T11:37:35.157552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.MasVnr...\nMasVnrType: Masonry veneer type\\\nMasVnrArea: Masonry veneer area in square feet","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"* Categorical feature & numerical feature\n* Values not missing at random\n* Missing percentage: 0.55% & 0.55%\n* All missing values appear simultaneously\n\nAccording to the mono plot, it seems that the missing values for these two features occur simultaneously. 'MasVnrType' represents the type of masonry veneer, while 'MasVnrArea' represents the area of masonry veneer. If the missing values for both of these features occur together, it could mean that these houses do not have any masonry veneer. Therefore, when the missing values occur simultaneously, we impute 'MasVnrType' with 'None' and 'MasVnrArea' with 0.","metadata":{}},{"cell_type":"code","source":"#show unique values of MasVnrType\ndata['MasVnrType'].value_counts(dropna = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.160395Z","iopub.execute_input":"2023-08-04T11:37:35.161156Z","iopub.status.idle":"2023-08-04T11:37:35.177060Z","shell.execute_reply.started":"2023-08-04T11:37:35.161111Z","shell.execute_reply":"2023-08-04T11:37:35.175877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# When missing values appears simultaneously, impute 'MasVnrType' with 'NA' and 'MasVnrArea' with 0.\ndata.loc[data['MasVnrType'].isnull() & data['MasVnrArea'].isnull(), ['MasVnrType','MasVnrArea']] = ['None',0.0]","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.178487Z","iopub.execute_input":"2023-08-04T11:37:35.179211Z","iopub.status.idle":"2023-08-04T11:37:35.191901Z","shell.execute_reply.started":"2023-08-04T11:37:35.179175Z","shell.execute_reply":"2023-08-04T11:37:35.190557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.Bsmt...\nBsmtQual: Evaluates the height of the basement\\\nBsmtCond: Evaluates the general condition of the basement\\\nBsmtExposure: Refers to walkout or garden level walls\\\nBsmtFinType1: Rating of basement finished area\\\nBsmtFinType2: Rating of basement finished area (if multiple types)","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"* All are Categorical features\n* <b>Some values not missing at random</b>\n* Missing percentage: 2.60% for 'BsmtExposure' and 'BsmtFinType2'; 2.53% for 'BsmtQual','BsmtCond', and 'BsmtFinType1'\n* Some values missing simultanouesly\n\nAccording to the mono plot, it seems that the missing values for Bsmt related features occur simultaneously. Moreover, we can always find these simultaneous missings at 'TotalBsmtSF' = 0, which could mean that these houses do not have basement. Therefore, at 'TotalBsmtSF' = 0, impute Bsmt related features with 'None'.","metadata":{}},{"cell_type":"code","source":"#creat a list for Bsmt related features\ncols = ['BsmtQual','BsmtCond','BsmtFinType1', 'BsmtExposure', 'BsmtFinType2']\n\n# impute with 'None' for features not missing at random (TotalBsmtSF = 0)\ndata.loc[data['TotalBsmtSF'] == 0, cols] = data.loc[data['TotalBsmtSF'] == 0, cols].fillna('None')\n\n#show unique values\nfor i in cols:\n    print(data[i].value_counts(dropna = False), '\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:35.202148Z","iopub.execute_input":"2023-08-04T11:37:35.202575Z","iopub.status.idle":"2023-08-04T11:37:35.222121Z","shell.execute_reply.started":"2023-08-04T11:37:35.202540Z","shell.execute_reply":"2023-08-04T11:37:35.221149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* <b>Some values missing at random</b>\\\nHowever, we still have missing values for 'BsmtExposure' and 'BsmtFinType2' after imputation. This is because now TotalBsmtSF != 0, so houses do have basements. So, values are missing at random. So, impute remaining missing values with mode since 'BsmtExposure' and 'BsmtFinType2' are categorical features.","metadata":{}},{"cell_type":"code","source":"#impute remaining missing values with mode\ndata['BsmtExposure'].fillna(data['BsmtExposure'].mode()[0], inplace = True)\ndata['BsmtFinType2'].fillna(data['BsmtFinType2'].mode()[0], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.223372Z","iopub.execute_input":"2023-08-04T11:37:35.224431Z","iopub.status.idle":"2023-08-04T11:37:35.236096Z","shell.execute_reply.started":"2023-08-04T11:37:35.224382Z","shell.execute_reply":"2023-08-04T11:37:35.234975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.Electrical\nElectrical system","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"* Categorical feature\n* Values missing at random\n* Missing percentage: 0.07%\n\nThe data description did not expect to have missing values for this feature. So I guess that this could happen either because it's a record mistake or because this property does not have electrical system indeed. \n\nIf it's a record mistake, we should impute it with mode, but if this property does not have electrical system indeed, it should be treated as an outlier. For our analysis, we assume it's a record mistake.","metadata":{}},{"cell_type":"code","source":"data['Electrical'].value_counts(dropna = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.237313Z","iopub.execute_input":"2023-08-04T11:37:35.238244Z","iopub.status.idle":"2023-08-04T11:37:35.251536Z","shell.execute_reply.started":"2023-08-04T11:37:35.238201Z","shell.execute_reply":"2023-08-04T11:37:35.250663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Electrical'].fillna(data['Electrical'].mode()[0], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.252967Z","iopub.execute_input":"2023-08-04T11:37:35.253721Z","iopub.status.idle":"2023-08-04T11:37:35.263489Z","shell.execute_reply.started":"2023-08-04T11:37:35.253686Z","shell.execute_reply":"2023-08-04T11:37:35.262502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6.FireplaceQu\nFireplace quality","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"* Categorical feature\n* Values not missing at random\n* Missing percentage: 47.26%\n\nMissing values indicate no FireplaceQu at the property, so impute with 'None'.","metadata":{}},{"cell_type":"code","source":"#show values\ndata['FireplaceQu'].value_counts(dropna = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.265141Z","iopub.execute_input":"2023-08-04T11:37:35.265892Z","iopub.status.idle":"2023-08-04T11:37:35.277970Z","shell.execute_reply.started":"2023-08-04T11:37:35.265839Z","shell.execute_reply":"2023-08-04T11:37:35.276472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#impute with 'None'\ndata['FireplaceQu'].fillna('None', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.280165Z","iopub.execute_input":"2023-08-04T11:37:35.281056Z","iopub.status.idle":"2023-08-04T11:37:35.287929Z","shell.execute_reply.started":"2023-08-04T11:37:35.281012Z","shell.execute_reply":"2023-08-04T11:37:35.286725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7.Garage...\n-GarageType: Garage location\\\n-GarageFinish: Interior finish of the garage\\\n-GarageQual: Garage quality\\\n-GarageCond: Garage condition\\\n-GarageYrBlt: Year garage was built","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"* Values not missing at random\n* Categorical features; GarageYrBlt is numerical\n* Missing percentages are: 5.55%\n\nAccording to the mono plot, it seems that the missing values for Garage related features occur simultaneously.Moreover, we can always find these simultaneous missing at 'GarageArea' = 0, which could mean that these houses do not have garage. Therefore, at 'GarageArea' = 0, we impute garage related features with 'None'.","metadata":{}},{"cell_type":"code","source":"# Plot the distribution of 'LotFrontage' values\nplt.figure(figsize=(5, 3))\nsns.distplot(data['GarageYrBlt'])\nplt.show()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:35.289478Z","iopub.execute_input":"2023-08-04T11:37:35.289857Z","iopub.status.idle":"2023-08-04T11:37:35.712512Z","shell.execute_reply.started":"2023-08-04T11:37:35.289825Z","shell.execute_reply":"2023-08-04T11:37:35.711318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems there are two central tendency of the distribution: one before 1980s and one after 1980. Since missing values indicate no garage, if we impute with 'None', we are going to have to dtypes for this features. So, we perform feature creation for GarageYrBlt ","metadata":{}},{"cell_type":"code","source":"#creat a list for Garage related features\ncols = ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'GarageYrBlt']\n\n# impute with 'None' for features not missing at random (GarageArea = 0)\ndata.loc[data['GarageArea'] == 0, cols] = data.loc[data['GarageArea'] == 0, cols].fillna('None')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:35.714187Z","iopub.execute_input":"2023-08-04T11:37:35.714596Z","iopub.status.idle":"2023-08-04T11:37:35.729208Z","shell.execute_reply.started":"2023-08-04T11:37:35.714556Z","shell.execute_reply":"2023-08-04T11:37:35.728175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature Creation \ndata['GarageYrBlt'] = data['GarageYrBlt'].apply(lambda x: 'None' if x == 'None' else ('New' if x > 1980 else 'Old'))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:35.730459Z","iopub.execute_input":"2023-08-04T11:37:35.730791Z","iopub.status.idle":"2023-08-04T11:37:35.741344Z","shell.execute_reply.started":"2023-08-04T11:37:35.730762Z","shell.execute_reply":"2023-08-04T11:37:35.740491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['GarageYrBlt'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.742404Z","iopub.execute_input":"2023-08-04T11:37:35.743894Z","iopub.status.idle":"2023-08-04T11:37:35.756838Z","shell.execute_reply.started":"2023-08-04T11:37:35.743844Z","shell.execute_reply":"2023-08-04T11:37:35.755990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8.PoolQC\nPool quality","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"* Categorical Feature\n* Values not missing at random\n* Missing percentage: 99.52%\n\nMissing values indicate no pool at the property.","metadata":{}},{"cell_type":"code","source":"#show values\ndata['PoolQC'].value_counts(dropna = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.758316Z","iopub.execute_input":"2023-08-04T11:37:35.758914Z","iopub.status.idle":"2023-08-04T11:37:35.767850Z","shell.execute_reply.started":"2023-08-04T11:37:35.758881Z","shell.execute_reply":"2023-08-04T11:37:35.766704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#impute with 'None'\ndata['PoolQC'].fillna('None', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.769179Z","iopub.execute_input":"2023-08-04T11:37:35.769494Z","iopub.status.idle":"2023-08-04T11:37:35.779314Z","shell.execute_reply.started":"2023-08-04T11:37:35.769466Z","shell.execute_reply":"2023-08-04T11:37:35.778353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 9.Fence\nFence quality","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"* Categorical Feature\n* Values not missing at random\n* Missing percentage: 80.75%\n\nFence means fence quality-type,missing values indicate no fence at the property. However, at this point we don't know for sure how fence influences the target. So, let's impute it with 'None' for now and review it later in feature engineering.","metadata":{}},{"cell_type":"code","source":"#show unique values\ndata['Fence'].value_counts(dropna = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.780625Z","iopub.execute_input":"2023-08-04T11:37:35.781507Z","iopub.status.idle":"2023-08-04T11:37:35.795947Z","shell.execute_reply.started":"2023-08-04T11:37:35.781475Z","shell.execute_reply":"2023-08-04T11:37:35.794744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#impute with 'None'\ndata['Fence'].fillna('None', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.797268Z","iopub.execute_input":"2023-08-04T11:37:35.797770Z","iopub.status.idle":"2023-08-04T11:37:35.810088Z","shell.execute_reply.started":"2023-08-04T11:37:35.797725Z","shell.execute_reply":"2023-08-04T11:37:35.809090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 10.MiscFeature\nMiscellaneous feature not covered in other categories","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"markdown","source":"* Categorical Feature\n* Values not missing at random\n* Missing percentage:96.30%\n\nMissing values indicate no MiscFeature at the property, so impute with 'None'.","metadata":{}},{"cell_type":"code","source":"#show unique values\ndata['MiscFeature'].value_counts(dropna = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.811465Z","iopub.execute_input":"2023-08-04T11:37:35.811930Z","iopub.status.idle":"2023-08-04T11:37:35.826091Z","shell.execute_reply.started":"2023-08-04T11:37:35.811895Z","shell.execute_reply":"2023-08-04T11:37:35.824881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#impute with 'None'\ndata['MiscFeature'].fillna('None', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.827326Z","iopub.execute_input":"2023-08-04T11:37:35.827673Z","iopub.status.idle":"2023-08-04T11:37:35.837307Z","shell.execute_reply.started":"2023-08-04T11:37:35.827627Z","shell.execute_reply":"2023-08-04T11:37:35.836020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.5.Check for Remaining Missing Values","metadata":{"tags":[]}},{"cell_type":"code","source":"data.isnull().any().any()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.838835Z","iopub.execute_input":"2023-08-04T11:37:35.839173Z","iopub.status.idle":"2023-08-04T11:37:35.874493Z","shell.execute_reply.started":"2023-08-04T11:37:35.839145Z","shell.execute_reply":"2023-08-04T11:37:35.873577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So far, no missing value remains. Let's proceed to treating outliers","metadata":{}},{"cell_type":"markdown","source":"## 4.6.Feature Encoding","metadata":{"tags":[]}},{"cell_type":"markdown","source":"### 4.6.1.Ordinal Mapping\nperform ordinal mapp for ordered features","metadata":{"tags":[]}},{"cell_type":"markdown","source":"* 10 - very excellent\n* 9 - excellent (Ex)\n* 8 - very good\n* 7 - good (Gd)\n* 6 - above average\n* 5 - average (TA)\n* 4 - below average\n* 3 - fair (Fa)\n* 2 - poor (Po)\n* 1 - very poor\n* 0 - None","metadata":{}},{"cell_type":"code","source":"data['GarageQual'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.875968Z","iopub.execute_input":"2023-08-04T11:37:35.876284Z","iopub.status.idle":"2023-08-04T11:37:35.884768Z","shell.execute_reply.started":"2023-08-04T11:37:35.876256Z","shell.execute_reply":"2023-08-04T11:37:35.883898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify categorical features in the dataset\ncat_features = data.select_dtypes(include=['object']).columns.tolist()\n\n# Define the ordered values\nordered_values = ['Ex', 'Gd', 'TA', 'Fa', 'Po']\n\n# Initialize an empty list to hold the features that contain ordered values\nordinal_features = []\n\n# Find features with ordered values\nfor i in cat_features:\n    \n    if any(value in data[i].unique() for value in ordered_values):\n        ordinal_features.append(i)\n\nprint('Ordinal features are:')        \nprint(ordinal_features)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.885817Z","iopub.execute_input":"2023-08-04T11:37:35.886156Z","iopub.status.idle":"2023-08-04T11:37:35.938911Z","shell.execute_reply.started":"2023-08-04T11:37:35.886128Z","shell.execute_reply":"2023-08-04T11:37:35.937488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check unique values for these features\nfor i in ordinal_features:\n    print(data[i].unique())","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.940483Z","iopub.execute_input":"2023-08-04T11:37:35.940897Z","iopub.status.idle":"2023-08-04T11:37:35.950577Z","shell.execute_reply.started":"2023-08-04T11:37:35.940863Z","shell.execute_reply":"2023-08-04T11:37:35.949107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop 'BsmtExposure'\nordinal_features_1 = [cols for cols in ordinal_features if (cols != 'BsmtExposure')]\nprint(ordinal_features_1)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.952220Z","iopub.execute_input":"2023-08-04T11:37:35.952545Z","iopub.status.idle":"2023-08-04T11:37:35.960292Z","shell.execute_reply.started":"2023-08-04T11:37:35.952516Z","shell.execute_reply":"2023-08-04T11:37:35.959009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# conduct ordinal encoding for these features\nfor i in ordinal_features_1:\n    data[i] = data[i].map({'Ex':9, 'Gd':7, 'TA':5, 'Fa':3, 'Po':2, 'None':0 })","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.961873Z","iopub.execute_input":"2023-08-04T11:37:35.962251Z","iopub.status.idle":"2023-08-04T11:37:35.987441Z","shell.execute_reply.started":"2023-08-04T11:37:35.962218Z","shell.execute_reply":"2023-08-04T11:37:35.986473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.6.2.Binary Mapping\nperform binary mapping for binary features","metadata":{"tags":[]}},{"cell_type":"code","source":"#binary variables are defined as number of unique values = 2 \nbin_features = [col for col in data.columns if data[col].nunique() == 2]\nbin_features","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:35.988764Z","iopub.execute_input":"2023-08-04T11:37:35.989178Z","iopub.status.idle":"2023-08-04T11:37:36.012901Z","shell.execute_reply.started":"2023-08-04T11:37:35.989149Z","shell.execute_reply":"2023-08-04T11:37:36.011793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying the binary mapping to binary columns\ndata['Street'] = data['Street'].map({'Pave': 1, \"Grvl\": 0})\ndata['Utilities'] = data['Utilities'].map({'AllPub': 1, \"NoSeWa\": 0})\ndata['CentralAir'] = data['CentralAir'].map({'Y': 1, \"N\": 0})","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:36.014422Z","iopub.execute_input":"2023-08-04T11:37:36.014807Z","iopub.status.idle":"2023-08-04T11:37:36.029121Z","shell.execute_reply.started":"2023-08-04T11:37:36.014774Z","shell.execute_reply":"2023-08-04T11:37:36.027613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.7.Treat Outliers","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Now that we have performed feature encoding for ordinal & binary features, it is now appropriate to distinguish between discrete and continous features for outliers treatment. ","metadata":{}},{"cell_type":"markdown","source":"### Numerical Features","metadata":{"tags":[]}},{"cell_type":"code","source":"#find out all numerical features\nnum_features = [cols for cols in data.select_dtypes(include = np.number).columns if cols != 'SalePrice']\nprint('Numerical features are:')\nprint(num_features)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:36.030637Z","iopub.execute_input":"2023-08-04T11:37:36.031033Z","iopub.status.idle":"2023-08-04T11:37:36.040503Z","shell.execute_reply.started":"2023-08-04T11:37:36.031000Z","shell.execute_reply":"2023-08-04T11:37:36.039181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Discrete Features","metadata":{}},{"cell_type":"code","source":"# Get the number of unique values for each numerical feature\nnum_unique_counts = data[num_features].nunique().sort_values()\n\n# Identify discrete features\ndiscrete_features = num_unique_counts[num_unique_counts < 30].index.tolist()\n\nprint('Discrete Features are:')\nprint(discrete_features)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:36.042271Z","iopub.execute_input":"2023-08-04T11:37:36.042748Z","iopub.status.idle":"2023-08-04T11:37:36.062423Z","shell.execute_reply.started":"2023-08-04T11:37:36.042707Z","shell.execute_reply":"2023-08-04T11:37:36.061494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Continous Features","metadata":{}},{"cell_type":"code","source":"continous_features = [cols for cols in num_features if (cols not in discrete_features)]\n\nprint('Continous Features are:')\nprint(continous_features)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:36.063807Z","iopub.execute_input":"2023-08-04T11:37:36.064359Z","iopub.status.idle":"2023-08-04T11:37:36.069956Z","shell.execute_reply.started":"2023-08-04T11:37:36.064327Z","shell.execute_reply":"2023-08-04T11:37:36.068729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Continous Features with Extreme Outliers","metadata":{"tags":[]}},{"cell_type":"code","source":"# Find all features where the maximum value is greater than three times the third quartile\ncf_with_extremo = []\n\nfor i in continous_features:\n    \n    thres = 3 \n    \n    Q1 = data[i].quantile(0.25)\n    Q3 = data[i].quantile(0.75)\n    min_val = data[i].min()\n    max_val = data[i].max()\n    \n    if (max_val > thres*Q3 and Q3 != 0) or (min_val < Q1/thres):\n        cf_with_extremo.append(i)\n        \nprint('Continous features with extreme outliers are:')\nprint(cf_with_extremo)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:36.071182Z","iopub.execute_input":"2023-08-04T11:37:36.071777Z","iopub.status.idle":"2023-08-04T11:37:36.120566Z","shell.execute_reply.started":"2023-08-04T11:37:36.071744Z","shell.execute_reply":"2023-08-04T11:37:36.119251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[cf_with_extremo].describe(percentiles = [0.003,0.01, 0.99, 0.997])","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:36.122158Z","iopub.execute_input":"2023-08-04T11:37:36.122489Z","iopub.status.idle":"2023-08-04T11:37:36.174820Z","shell.execute_reply.started":"2023-08-04T11:37:36.122460Z","shell.execute_reply":"2023-08-04T11:37:36.173718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Box Plot","metadata":{"tags":[]}},{"cell_type":"code","source":"#Function for visualizing continous features, box plot\ndef box_plot(x):\n    ax = sns.boxplot(y = data[x], color = 'darkcyan', showfliers = True, showmeans = True, \n                     meanprops={\"marker\":\"s\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"crimson\"})\n    ax.set_ylabel('')\n    ax.set_title('{}'.format(x), fontsize = 14, fontweight = 'bold', pad = 5)\n    ax.patch.set_edgecolor('black')\n    ax.patch.set_linewidth(1.5)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:36.176098Z","iopub.execute_input":"2023-08-04T11:37:36.176447Z","iopub.status.idle":"2023-08-04T11:37:36.184031Z","shell.execute_reply.started":"2023-08-04T11:37:36.176417Z","shell.execute_reply":"2023-08-04T11:37:36.182972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = [14,40])\nfor i in range(len(cf_with_extremo)):\n    plt.subplot(10,5,i+1)\n    box_plot(cf_with_extremo[i])\nplt.tight_layout()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:36.185433Z","iopub.execute_input":"2023-08-04T11:37:36.185782Z","iopub.status.idle":"2023-08-04T11:37:39.163595Z","shell.execute_reply.started":"2023-08-04T11:37:36.185751Z","shell.execute_reply":"2023-08-04T11:37:39.162421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove Outliers and Visualize Effects on a Copy","metadata":{"tags":[]}},{"cell_type":"code","source":"data1 = data.copy()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:39.165281Z","iopub.execute_input":"2023-08-04T11:37:39.165826Z","iopub.status.idle":"2023-08-04T11:37:39.173157Z","shell.execute_reply.started":"2023-08-04T11:37:39.165784Z","shell.execute_reply":"2023-08-04T11:37:39.172037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1 = data.copy()\n\n#Function for visualizing continous features, box plot\ndef box_plot(x):\n    ax = sns.boxplot(y = data1[x], color = 'darkcyan', showfliers = True, showmeans = True, \n                     meanprops={\"marker\":\"s\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"crimson\"})\n    ax.set_ylabel('')\n    ax.set_title('{}'.format(x), fontsize = 14, fontweight = 'bold', pad = 5)\n    ax.patch.set_edgecolor('black')\n    ax.patch.set_linewidth(1.5)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:39.174615Z","iopub.execute_input":"2023-08-04T11:37:39.175004Z","iopub.status.idle":"2023-08-04T11:37:39.184999Z","shell.execute_reply.started":"2023-08-04T11:37:39.174972Z","shell.execute_reply":"2023-08-04T11:37:39.183869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1 = data1[data1['LotFrontage'] < 300]\ndata1 = data1[data1['LotArea'] < 70000] \ndata1 = data1[data1['MasVnrArea'] < 1200]\ndata1 = data1[data1['WoodDeckSF'] < 800]\ndata1 = data1[data1['BsmtUnfSF'] < 2300]","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:39.186699Z","iopub.execute_input":"2023-08-04T11:37:39.187036Z","iopub.status.idle":"2023-08-04T11:37:39.211815Z","shell.execute_reply.started":"2023-08-04T11:37:39.187007Z","shell.execute_reply":"2023-08-04T11:37:39.210630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:39.213412Z","iopub.execute_input":"2023-08-04T11:37:39.213791Z","iopub.status.idle":"2023-08-04T11:37:39.220330Z","shell.execute_reply.started":"2023-08-04T11:37:39.213758Z","shell.execute_reply":"2023-08-04T11:37:39.219200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = [18,32])\nfor i in range(len(cf_with_extremo)):\n    plt.subplot(5,5,i+1)\n    box_plot(cf_with_extremo[i])\nplt.tight_layout()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:37:39.222211Z","iopub.execute_input":"2023-08-04T11:37:39.222675Z","iopub.status.idle":"2023-08-04T11:37:41.982846Z","shell.execute_reply.started":"2023-08-04T11:37:39.222613Z","shell.execute_reply":"2023-08-04T11:37:41.982043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Apply Treatment to Preprocessing Data \nWhen we are satisfied with the box plot after removing outliers, we apply it to data we are preprocessing.","metadata":{}},{"cell_type":"code","source":"data = data1\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:37:41.984125Z","iopub.execute_input":"2023-08-04T11:37:41.984912Z","iopub.status.idle":"2023-08-04T11:37:41.992024Z","shell.execute_reply.started":"2023-08-04T11:37:41.984878Z","shell.execute_reply":"2023-08-04T11:37:41.990863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before outlier treatment, we have 1,460 samples. After outlier treatment, we have 1449 samples, which means 11 samples are lost due to outlier treatment","metadata":{}},{"cell_type":"markdown","source":"## 4.8.EDA \nIt's now a good point to perform EDA to have a general visualization of the data.","metadata":{"tags":[]}},{"cell_type":"markdown","source":"### 4.8.1.Discrete/Categorical Variables v.s. Target","metadata":{"tags":[]}},{"cell_type":"code","source":"# Function for visualizing discrete/categorical variables against SalePrice, boxplot\ndef box_plot2(x, y):\n    ax = sns.boxplot(x=data[x], y=data[y], order=sorted_categories[x], palette = 'Set2', showmeans=True,\n                     meanprops={\"marker\": \"s\", \"markerfacecolor\": \"white\", \"markeredgecolor\": \"crimson\"})\n    ax.set_ylabel('')\n    ax.set_title('{}'.format(x), fontsize=12, fontweight='bold', pad=5)\n    ax.patch.set_edgecolor('black')\n    ax.patch.set_linewidth(1.5)\n    plt.title('{}'.format(x), fontsize=16)\n\n# Assuming 'data' is your DataFrame containing the data\ncat_cols = [cols for cols in data.columns if (cols != 'SalePrice') & (cols not in continous_features)]\n\n# Calculate the mean of 'SalePrice' for each category in each categorical feature\nmedians = {}\nfor col in cat_cols:\n    medians[col] = data.groupby(col)['SalePrice'].median()\n\n# Sort the categorical features based on the mean of 'SalePrice'\nsorted_categories = {col: sorted(data[col].unique(), key=lambda x: medians[col][x]) for col in cat_cols}\n\nnum_rows = (len(cat_cols) + 3) // 4\nplt.figure(figsize=[20, num_rows * 6])\nfor i in range(len(cat_cols)):\n    plt.subplot(num_rows, 4, i + 1)\n    box_plot2(cat_cols[i], 'SalePrice')\nplt.tight_layout()\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-04T11:37:41.993307Z","iopub.execute_input":"2023-08-04T11:37:41.993680Z","iopub.status.idle":"2023-08-04T11:38:08.004130Z","shell.execute_reply.started":"2023-08-04T11:37:41.993630Z","shell.execute_reply":"2023-08-04T11:38:08.001745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.8.2.Numerical feautures v.s. Target","metadata":{"tags":[]}},{"cell_type":"code","source":"# Function for visualizing numerical variables against SalePrice, scatterplot\ndef scatter_plot(x):\n    ax = sns.scatterplot(x=data[x], y=data['SalePrice'], alpha=0.35, linewidth=0)\n    ax.set_title('{} vs SalePrice'.format(x), fontsize=12, pad=5)\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.patch.set_edgecolor('black')\n    ax.patch.set_linewidth(1.5)\n\nplt.figure(figsize=[18, 32])\nfor i in range(len(continous_features)):\n    plt.subplot(13, 4, i + 1)\n    scatter_plot(continous_features[i])\nplt.tight_layout()\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-04T11:38:08.005825Z","iopub.execute_input":"2023-08-04T11:38:08.006240Z","iopub.status.idle":"2023-08-04T11:38:13.804319Z","shell.execute_reply.started":"2023-08-04T11:38:08.006204Z","shell.execute_reply":"2023-08-04T11:38:13.803190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.9.One-Hot Encoding\nperform one-hot encoding for nominal features","metadata":{"tags":[]}},{"cell_type":"code","source":"#find nominal features\nnomin_features = data.select_dtypes(exclude = np.number).columns\nnomin_features","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:13.806002Z","iopub.execute_input":"2023-08-04T11:38:13.806444Z","iopub.status.idle":"2023-08-04T11:38:13.816319Z","shell.execute_reply.started":"2023-08-04T11:38:13.806402Z","shell.execute_reply":"2023-08-04T11:38:13.815125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#perform one-hot encoding to nominal features\ndata_dummy = pd.get_dummies(data[nomin_features], drop_first = True)\ndata_dummy.head()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-04T11:38:13.817913Z","iopub.execute_input":"2023-08-04T11:38:13.818373Z","iopub.status.idle":"2023-08-04T11:38:13.955828Z","shell.execute_reply.started":"2023-08-04T11:38:13.818338Z","shell.execute_reply":"2023-08-04T11:38:13.954735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#concat dummy features to data\ndata = pd.concat([data, data_dummy], axis = 1)\n\n#drop nominal features\ndata = data.drop(nomin_features, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:13.957470Z","iopub.execute_input":"2023-08-04T11:38:13.958009Z","iopub.status.idle":"2023-08-04T11:38:13.972733Z","shell.execute_reply.started":"2023-08-04T11:38:13.957967Z","shell.execute_reply":"2023-08-04T11:38:13.971606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:13.989020Z","iopub.execute_input":"2023-08-04T11:38:13.989935Z","iopub.status.idle":"2023-08-04T11:38:13.997138Z","shell.execute_reply.started":"2023-08-04T11:38:13.989896Z","shell.execute_reply":"2023-08-04T11:38:13.995818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.10.Dimensionality Reduction","metadata":{}},{"cell_type":"markdown","source":"### 4.10.1.Drop features with low variance\nSince we now have up to 246 features after all previous operations, we may consider reduce dimensionality by drop features with rather small variance. ","metadata":{}},{"cell_type":"code","source":"# Calculate variance of each feature\nfeature_var = data.var()\n\n# Find features with variance close to 0\nlow_var_features = feature_var[feature_var < 0.001]\n\nlow_var_features","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:13.998732Z","iopub.execute_input":"2023-08-04T11:38:13.999112Z","iopub.status.idle":"2023-08-04T11:38:14.022003Z","shell.execute_reply.started":"2023-08-04T11:38:13.999079Z","shell.execute_reply":"2023-08-04T11:38:14.020850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"low_var_features_list = low_var_features.index.tolist()\nprint(low_var_features_list)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:14.023680Z","iopub.execute_input":"2023-08-04T11:38:14.024125Z","iopub.status.idle":"2023-08-04T11:38:14.029834Z","shell.execute_reply.started":"2023-08-04T11:38:14.024072Z","shell.execute_reply":"2023-08-04T11:38:14.028711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop(low_var_features_list,axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:14.031206Z","iopub.execute_input":"2023-08-04T11:38:14.031538Z","iopub.status.idle":"2023-08-04T11:38:14.043223Z","shell.execute_reply.started":"2023-08-04T11:38:14.031508Z","shell.execute_reply":"2023-08-04T11:38:14.042069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.10.2.Address Multicolinearity\nDimensionality reduction can also be achieved by picking among features with multicolinearity that has the highest correlation with target.","metadata":{}},{"cell_type":"markdown","source":"#### Analysis","metadata":{}},{"cell_type":"code","source":"#Visualize Correlation \nGarage_SalePrice = ['GarageArea', 'GarageCars', 'GarageCond', 'GarageQual','GarageFinish_None', 'GarageType_None', 'GarageYrBlt_None', 'SalePrice']\n\nplt.figure(figsize=(10,10))\ng = sns.heatmap(data[Garage_SalePrice].corr(),annot=True,cmap=\"RdYlGn\")","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:14.044844Z","iopub.execute_input":"2023-08-04T11:38:14.045178Z","iopub.status.idle":"2023-08-04T11:38:14.831145Z","shell.execute_reply.started":"2023-08-04T11:38:14.045148Z","shell.execute_reply":"2023-08-04T11:38:14.829927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the correlation matrix, I want to develop an algorithm:\n1. Compare between features with absolute correlation higher than 0.8.\nIn this case\\\nGroup1: GarageArea & GarageCars\\\nGroup2: GarageCond & GarageQual\\\nGroup3: GarageFinish_None/GarageType_None/GarageYrBlt_None & GarageQual\\\nGroup4: GarageFinish_None/GarageType_None/GarageYrBlt_None & GarageCond \n3. Pick features that has higher correlation with SalePrice:\\\nGroup1: Garage_Cars\\\nGroup2: GargeQual\\\nGroup3: GarageQual\\\nGroup4: GarageCond\n\nRemove duplicates and repeat step1 & 2, features we need are: GarageCars, GarageQual","metadata":{}},{"cell_type":"markdown","source":"#### Develop Algorithm","metadata":{}},{"cell_type":"code","source":"# Calculate the correlation matrix\ncorr_matrix = data.corr()\n\n# Find features with correlation higher than 0.8\nhighly_correlated_features = set()\n\nfor i in range(len(corr_matrix.columns)):\n    for j in range(i):\n        if abs(corr_matrix.iloc[i, j]) > 0.8:\n            colname_i = corr_matrix.columns[i]\n            colname_j = corr_matrix.columns[j]\n            highly_correlated_features.add((colname_i, colname_j))\n\nhighly_correlated_features","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-04T11:38:14.832881Z","iopub.execute_input":"2023-08-04T11:38:14.833282Z","iopub.status.idle":"2023-08-04T11:38:15.959629Z","shell.execute_reply.started":"2023-08-04T11:38:14.833245Z","shell.execute_reply":"2023-08-04T11:38:15.958573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the correlation of each feature with the target\ncorr_with_target = data.corrwith(data['SalePrice'])\n\n# Re-initialize the set of features to keep\nkeep_features = set()\n\nfor feature_pair in highly_correlated_features:\n    feature1, feature2 = feature_pair\n    \n    # Compare the absolute correlation with target\n    if abs(corr_with_target[feature1]) >= abs(corr_with_target[feature2]):\n        keep_features.add(feature1)\n    else:\n        keep_features.add(feature2)\n\n# Now we loop until no pair of kept features has a correlation above 0.8\nwhile True:\n    # Calculate the correlation matrix for the kept features\n    corr_matrix_keep = data[keep_features].corr().abs()\n    \n    # Find pairs of features that have a correlation above 0.8\n    corr_pairs = [(i, j) for i in range(len(corr_matrix_keep)) for j in range(i) if abs(corr_matrix_keep.iloc[i, j]) > 0.8]\n    \n    # If no such pairs are found, we can break the loop\n    if not corr_pairs:\n        break\n    \n    # Otherwise, we remove one feature from each pair\n    for i, j in corr_pairs:\n        feature1 = corr_matrix_keep.columns[i]\n        feature2 = corr_matrix_keep.columns[j]\n        \n        # Compare the absolute correlation with target\n        if abs(corr_with_target[feature1]) >= abs(corr_with_target[feature2]):\n            # Check if the feature is still in the set before removing it\n            if feature2 in keep_features:\n                keep_features.remove(feature2)\n        else:\n            # Check if the feature is still in the set before removing it\n            if feature1 in keep_features:\n                keep_features.remove(feature1)\n\nprint('Features to keep are:')\nprint(keep_features)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:15.961242Z","iopub.execute_input":"2023-08-04T11:38:15.961586Z","iopub.status.idle":"2023-08-04T11:38:16.088918Z","shell.execute_reply.started":"2023-08-04T11:38:15.961556Z","shell.execute_reply":"2023-08-04T11:38:16.087799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I am happy to see my algorithm choose to keep 'GarageCars' & 'GarageQual' as it is supposed to. ","metadata":{}},{"cell_type":"code","source":"# The features to drop are those that are in the original set of highly correlated features but not in the keep_features set\noriginal_highly_correlated_features = set()\nfor pair in highly_correlated_features:\n    original_highly_correlated_features.update(pair)\n\ndrop_highly_correlated_features = list(original_highly_correlated_features - keep_features)\n\nprint('Features to drop are:')\nprint(drop_highly_correlated_features)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:16.090430Z","iopub.execute_input":"2023-08-04T11:38:16.090885Z","iopub.status.idle":"2023-08-04T11:38:16.099649Z","shell.execute_reply.started":"2023-08-04T11:38:16.090841Z","shell.execute_reply":"2023-08-04T11:38:16.098595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop(drop_highly_correlated_features, axis =1)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:16.101135Z","iopub.execute_input":"2023-08-04T11:38:16.101468Z","iopub.status.idle":"2023-08-04T11:38:16.117414Z","shell.execute_reply.started":"2023-08-04T11:38:16.101440Z","shell.execute_reply":"2023-08-04T11:38:16.116377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Export Cleaned Data","metadata":{}},{"cell_type":"code","source":"# # export preprocessed data\n# data.to_csv('preprocessed_data.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:16.118841Z","iopub.execute_input":"2023-08-04T11:38:16.119802Z","iopub.status.idle":"2023-08-04T11:38:16.136060Z","shell.execute_reply.started":"2023-08-04T11:38:16.119768Z","shell.execute_reply":"2023-08-04T11:38:16.134922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.Model Building","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## 5.1.Feature Scalling","metadata":{"tags":[]}},{"cell_type":"code","source":"# split into train and test\ndata_train, data_test = train_test_split(data, train_size=0.7, test_size = 0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:16.137176Z","iopub.execute_input":"2023-08-04T11:38:16.137476Z","iopub.status.idle":"2023-08-04T11:38:16.152047Z","shell.execute_reply.started":"2023-08-04T11:38:16.137449Z","shell.execute_reply":"2023-08-04T11:38:16.151047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perform feature scalling for numerical features except for ordinal_features_1, bin_features, and data_dummy.columns","metadata":{}},{"cell_type":"code","source":"num_features = data.select_dtypes(include = np.number).columns\n\nfeatures_to_scal = [col for col in num_features if (col != 'SalePrice') & (col not in ordinal_features) \n                    & (col not in bin_features) & (col not in data_dummy.columns)]\n\nprint('Features_to_scal are:')\nprint(features_to_scal)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:16.153357Z","iopub.execute_input":"2023-08-04T11:38:16.153799Z","iopub.status.idle":"2023-08-04T11:38:16.163543Z","shell.execute_reply.started":"2023-08-04T11:38:16.153757Z","shell.execute_reply":"2023-08-04T11:38:16.162475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scalling by standardization\nscaler = StandardScaler()\n\ndata_train[features_to_scal] = scaler.fit_transform(data_train[features_to_scal])\ndata_test[features_to_scal] = scaler.transform(data_test[features_to_scal])","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:16.165003Z","iopub.execute_input":"2023-08-04T11:38:16.165397Z","iopub.status.idle":"2023-08-04T11:38:16.194027Z","shell.execute_reply.started":"2023-08-04T11:38:16.165359Z","shell.execute_reply":"2023-08-04T11:38:16.193064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seperate features from target\nX_train = data_train.drop('SalePrice', axis = 1)\ny_train = data_train['SalePrice']\n\nX_test = data_test.drop('SalePrice', axis = 1)\ny_test = data_test['SalePrice']","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:16.195634Z","iopub.execute_input":"2023-08-04T11:38:16.196332Z","iopub.status.idle":"2023-08-04T11:38:16.208176Z","shell.execute_reply.started":"2023-08-04T11:38:16.196289Z","shell.execute_reply":"2023-08-04T11:38:16.206865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2.Linear Regression","metadata":{}},{"cell_type":"code","source":"#function for building linear regression model using statsmodel api\ndef build_model(cols):\n    # Add a constant\n    X_train_lm = sm.add_constant(X_train[cols], has_constant = 'add')\n    # fitting model to data\n    lr = sm.OLS(y_train, X_train_lm).fit()\n    return lr\n\nlr = build_model(X_train.columns)\n\nX_train_lm = sm.add_constant(X_train, has_constant = 'add')\ny_train_pred_lm = lr.predict(X_train_lm)\nprint('Train R2 score      : ', r2_score(y_train, y_train_pred_lm))\nprint('Train MAE           : ', round(mean_absolute_error(y_train, y_train_pred_lm),2))\nprint('Train RMSE          : ', round(mean_squared_error(y_train, y_train_pred_lm, squared = False),2), '\\n')\n\n\nX_test_lm = sm.add_constant(X_test, has_constant = 'add')\ny_test_pred_lm = lr.predict(X_test_lm)\nprint('Test R2 score       : ', r2_score(y_test, y_test_pred_lm))\nprint('Test MAE           : ', round(mean_absolute_error(y_test, y_test_pred_lm),2))\nprint('Test RMSE          : ', round(mean_squared_error(y_test, y_test_pred_lm, squared = False),2), '\\n')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:16.209752Z","iopub.execute_input":"2023-08-04T11:38:16.210092Z","iopub.status.idle":"2023-08-04T11:38:16.599698Z","shell.execute_reply.started":"2023-08-04T11:38:16.210063Z","shell.execute_reply":"2023-08-04T11:38:16.598090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At this point, the performance of linear regression is not ideal, so we need to perform further operations to improve the overall performance.","metadata":{}},{"cell_type":"markdown","source":"## 5.3.Logarithmic Transformation for Target\nWe have previously observed in 3.1.Target Distribution that our target is right-skewed. By logarithmic transformation, we make it more close to a normal distribution.","metadata":{}},{"cell_type":"code","source":"y_train = np.log(y_train)\ny_test = np.log(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:16.602240Z","iopub.execute_input":"2023-08-04T11:38:16.603318Z","iopub.status.idle":"2023-08-04T11:38:16.623102Z","shell.execute_reply.started":"2023-08-04T11:38:16.603255Z","shell.execute_reply":"2023-08-04T11:38:16.621237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.4.Feature Selection using RFE\nWith our logarithmic transformed target, we use â€˜Recursive Feature Eliminationâ€™ model to eliminate features with little contribution to model training. Meanwhile, n_features_to_select is set to be 100 but is flexible to change. ","metadata":{}},{"cell_type":"code","source":"#importing utility\nfrom sklearn.feature_selection import RFE\n\n#Eliminating features using RFE\nlm = LinearRegression()\nselector = RFE(estimator = lm, n_features_to_select = 100)\nselector.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:16.625802Z","iopub.execute_input":"2023-08-04T11:38:16.627356Z","iopub.status.idle":"2023-08-04T11:38:19.114717Z","shell.execute_reply.started":"2023-08-04T11:38:16.627290Z","shell.execute_reply":"2023-08-04T11:38:19.112406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features selected bt rfe\ncols = X_train.columns[selector.support_]\ncols","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-04T11:38:19.121052Z","iopub.execute_input":"2023-08-04T11:38:19.127387Z","iopub.status.idle":"2023-08-04T11:38:19.146993Z","shell.execute_reply.started":"2023-08-04T11:38:19.127327Z","shell.execute_reply":"2023-08-04T11:38:19.144132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#updated training and test sets\nX_train_new = X_train[cols]\nX_test_new = X_test[cols]","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:19.154476Z","iopub.execute_input":"2023-08-04T11:38:19.155959Z","iopub.status.idle":"2023-08-04T11:38:19.168717Z","shell.execute_reply.started":"2023-08-04T11:38:19.155897Z","shell.execute_reply":"2023-08-04T11:38:19.167344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.5.Try with Different Linear Models","metadata":{}},{"cell_type":"markdown","source":"### 5.5.1.Lasso\nLasso uses L1 hyperparameter to penalize features with multicolinearity by assigning zero to predictive parameters. So, it helps us to further eliminate features with multicolinearity.","metadata":{}},{"cell_type":"markdown","source":"#### Parameter Optimization","metadata":{}},{"cell_type":"code","source":"# list of alphas to tune\n\nparams = {'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n\n\nlasso = Lasso()\n\n# cross validation\nfolds = 5\nmodel_cv = GridSearchCV(estimator = lasso, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \n\nmodel_cv.fit(X_train_new, y_train) \n\n# Print best fit hyperparameter alpha\nprint(model_cv.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:19.180940Z","iopub.execute_input":"2023-08-04T11:38:19.182147Z","iopub.status.idle":"2023-08-04T11:38:25.081278Z","shell.execute_reply.started":"2023-08-04T11:38:19.182093Z","shell.execute_reply":"2023-08-04T11:38:25.079800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Prediction","metadata":{}},{"cell_type":"code","source":"# Lasso Model for best param\nlasso = Lasso(alpha=0.001)\nlasso.fit(X_train_new, y_train)\n\ny_train_pred_lasso = lasso.predict(X_train_new)\nprint('Train R2 Score      : ', round(r2_score(y_train, y_train_pred_lasso),4))\nprint('Train MAE           : ', round(mean_absolute_error(y_train, y_train_pred_lasso),4))\nprint('Train RMSE          : ', round(mean_squared_error(y_train, y_train_pred_lasso, squared = False),4), '\\n')\n\ny_test_pred_lasso = lasso.predict(X_test_new)\nprint('Test R2 Score       : ', round(r2_score(y_test, y_test_pred_lasso),4))\nprint('Test MAE            : ', round(mean_absolute_error(y_test, y_test_pred_lasso),4))\nprint('Test RMSE           : ', round(mean_squared_error(y_test, y_test_pred_lasso, squared = False),4))","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:25.082934Z","iopub.execute_input":"2023-08-04T11:38:25.083914Z","iopub.status.idle":"2023-08-04T11:38:25.171010Z","shell.execute_reply.started":"2023-08-04T11:38:25.083872Z","shell.execute_reply":"2023-08-04T11:38:25.169186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Predicted SalePrice","metadata":{}},{"cell_type":"markdown","source":"Since we performed logarithmatic transform to SalePrice, we will need to use use np.exp() to expand SalePrice to its original scale.","metadata":{}},{"cell_type":"code","source":"y_test_pred_lasso","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-04T11:38:25.173467Z","iopub.execute_input":"2023-08-04T11:38:25.175042Z","iopub.status.idle":"2023-08-04T11:38:25.206176Z","shell.execute_reply.started":"2023-08-04T11:38:25.174992Z","shell.execute_reply":"2023-08-04T11:38:25.204948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.5.2.Rdige","metadata":{}},{"cell_type":"markdown","source":"#### Hyperparameter Optimization","metadata":{}},{"cell_type":"code","source":"# list of alphas to tune\nparams = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n\nridge = Ridge()\n\n# cross validation\nfolds = 5\nmodel_cv = GridSearchCV(estimator = ridge, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error',  \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \nmodel_cv.fit(X_train_new, y_train) \n\n# Print best fit hyperparameter alpha\nprint(model_cv.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:25.208952Z","iopub.execute_input":"2023-08-04T11:38:25.210750Z","iopub.status.idle":"2023-08-04T11:38:32.861164Z","shell.execute_reply.started":"2023-08-04T11:38:25.210688Z","shell.execute_reply":"2023-08-04T11:38:32.859722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Prediction","metadata":{}},{"cell_type":"code","source":"# Ridge Model for best param\nridge = Ridge(alpha = 10.0)\nridge.fit(X_train_new, y_train)\n\ny_train_pred_ridge = ridge.predict(X_train_new)\nprint('Train R2 Score      : ', round(r2_score(y_train, y_train_pred_ridge),4))\nprint('Train MAE           : ', round(mean_absolute_error(y_train, y_train_pred_ridge),4))\nprint('Train RMSE          : ', round(mean_squared_error(y_train, y_train_pred_ridge, squared = False),4), '\\n')\n\ny_test_pred_ridge = ridge.predict(X_test_new)\nprint('Test R2 Score       : ', round(r2_score(y_test, y_test_pred_ridge),4))\nprint('Test MAE            : ', round(mean_absolute_error(y_test, y_test_pred_ridge),4))\nprint('Test RMSE           : ', round(mean_squared_error(y_test, y_test_pred_ridge, squared = False),4))","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:32.863172Z","iopub.execute_input":"2023-08-04T11:38:32.864728Z","iopub.status.idle":"2023-08-04T11:38:32.941869Z","shell.execute_reply.started":"2023-08-04T11:38:32.864677Z","shell.execute_reply":"2023-08-04T11:38:32.940202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.5.3.Elastic Net","metadata":{}},{"cell_type":"markdown","source":"#### Hyperparameter Optimization","metadata":{}},{"cell_type":"code","source":"# list of alphas to tune\nparams = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ],\n          'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n\n\nen = ElasticNet()\n\n# cross validation\nfolds = 5\nmodel_cv = GridSearchCV(estimator = en, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1,\n                        n_jobs=-1)            \n\nmodel_cv.fit(X_train_new, y_train) \n\n# Print best fit hyperparameter alpha\nprint(model_cv.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:32.950045Z","iopub.execute_input":"2023-08-04T11:38:32.956840Z","iopub.status.idle":"2023-08-04T11:38:41.829231Z","shell.execute_reply.started":"2023-08-04T11:38:32.956769Z","shell.execute_reply":"2023-08-04T11:38:41.827557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Prediction","metadata":{}},{"cell_type":"code","source":"# ElasticNet Model for best param\nen = ElasticNet(alpha=0.001, l1_ratio = 0.4)\nen.fit(X_train_new, y_train)\n\ny_train_pred_en = en.predict(X_train_new)\nprint('Train R2 Score      : ', round(r2_score(y_train, y_train_pred_en),4))\nprint('Train MAE           : ', round(mean_absolute_error(y_train, y_train_pred_en),4))\nprint('Train RMSE          : ', round(mean_squared_error(y_train, y_train_pred_en, squared = False),4), '\\n')\n\ny_test_pred_en = en.predict(X_test_new)\nprint('Test R2 Score       : ', round(r2_score(y_test, y_test_pred_en),4))\nprint('Test MAE            : ', round(mean_absolute_error(y_test, y_test_pred_en),4))\nprint('Test RMSE           : ', round(mean_squared_error(y_test, y_test_pred_en, squared = False),4))","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:41.838690Z","iopub.execute_input":"2023-08-04T11:38:41.844172Z","iopub.status.idle":"2023-08-04T11:38:41.921749Z","shell.execute_reply.started":"2023-08-04T11:38:41.844090Z","shell.execute_reply":"2023-08-04T11:38:41.920239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Evalution","metadata":{}},{"cell_type":"code","source":"#Rdige\nprint('--Rdige--')\ny_train_pred_ridge = ridge.predict(X_train_new)\nprint('Train R2 Score      : ', round(r2_score(y_train, y_train_pred_ridge),4))\nprint('Train MAE           : ', round(mean_absolute_error(y_train, y_train_pred_ridge),4))\nprint('Train RMSE          : ', round(mean_squared_error(y_train, y_train_pred_ridge, squared = False),4), '\\n')\n\ny_test_pred_ridge = ridge.predict(X_test_new)\nprint('Test R2 Score       : ', round(r2_score(y_test, y_test_pred_ridge),4))\nprint('Test MAE            : ', round(mean_absolute_error(y_test, y_test_pred_ridge),4))\nprint('Test RMSE           : ', round(mean_squared_error(y_test, y_test_pred_ridge, squared = False),4), '\\n')\n\n#Lasso\nprint('--Lasso--')\ny_train_pred_lasso = lasso.predict(X_train_new)\nprint('Train R2 Score      : ', round(r2_score(y_train, y_train_pred_lasso),4))\nprint('Train MAE           : ', round(mean_absolute_error(y_train, y_train_pred_lasso),4))\nprint('Train RMSE          : ', round(mean_squared_error(y_train, y_train_pred_lasso, squared = False),4), '\\n')\n\ny_test_pred_lasso = lasso.predict(X_test_new)\nprint('Test R2 Score       : ', round(r2_score(y_test, y_test_pred_lasso),4))\nprint('Test MAE            : ', round(mean_absolute_error(y_test, y_test_pred_lasso),4))\nprint('Test RMSE           : ', round(mean_squared_error(y_test, y_test_pred_lasso, squared = False),4), '\\n')\n\n#Elastic Net\nprint('--Elastic Net--')\ny_train_pred_en = en.predict(X_train_new)\nprint('Train R2 Score      : ', round(r2_score(y_train, y_train_pred_en),4))\nprint('Train MAE           : ', round(mean_absolute_error(y_train, y_train_pred_en),4))\nprint('Train RMSE          : ', round(mean_squared_error(y_train, y_train_pred_en, squared = False),4), '\\n')\n\ny_test_pred_en = en.predict(X_test_new)\nprint('Test R2 Score       : ', round(r2_score(y_test, y_test_pred_en),4))\nprint('Test MAE            : ', round(mean_absolute_error(y_test, y_test_pred_en),4))\nprint('Test RMSE           : ', round(mean_squared_error(y_test, y_test_pred_en, squared = False),4), '\\n')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:41.930512Z","iopub.execute_input":"2023-08-04T11:38:41.935821Z","iopub.status.idle":"2023-08-04T11:38:42.037950Z","shell.execute_reply.started":"2023-08-04T11:38:41.935747Z","shell.execute_reply":"2023-08-04T11:38:42.036459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The 3 models have similar performance in terms of Test R2 Score(around 0.9), MAE (around 0.08), RMSE (around 0.11). Noticably, Ridge has the best performance -- it has the highest Test R2 score (0.9092), meaning that it has the best fitting effectiveness; it has the lowest MAE (0.0809), meaning that it generates the least errors on average; it also has the lowest RMSE (0.1148), meaning that it is least susceptible to noises and outliers. ","metadata":{}},{"cell_type":"markdown","source":"## 5.6.Important Features","metadata":{}},{"cell_type":"markdown","source":"### Coefficients of Ridge","metadata":{}},{"cell_type":"code","source":"ridge_df = pd.DataFrame({'Features': ridge.feature_names_in_, 'Coefficients': ridge.coef_})\nridge_df = ridge_df.sort_values('Coefficients', ascending = False).reset_index().drop('index', axis = 1)\nridge_df","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-04T11:38:42.046571Z","iopub.execute_input":"2023-08-04T11:38:42.051938Z","iopub.status.idle":"2023-08-04T11:38:42.113945Z","shell.execute_reply.started":"2023-08-04T11:38:42.051849Z","shell.execute_reply":"2023-08-04T11:38:42.112397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Important Features","metadata":{}},{"cell_type":"code","source":"important_df = ridge_df[abs(ridge_df.Coefficients) > 0.07].sort_values('Coefficients', ascending = False).reset_index().drop('index', axis = 1)\nimportant_df","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.116425Z","iopub.execute_input":"2023-08-04T11:38:42.117218Z","iopub.status.idle":"2023-08-04T11:38:42.145530Z","shell.execute_reply.started":"2023-08-04T11:38:42.117158Z","shell.execute_reply":"2023-08-04T11:38:42.144355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate Multicolinearity by VIF","metadata":{}},{"cell_type":"code","source":"#function to check for the VIF values of the feature variables. \ndef get_vif(cols):\n    # Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n    vif = pd.DataFrame()\n    vif['Features'] = X_train[cols].columns\n    vif['VIF'] = [variance_inflation_factor(X_train[cols].values, i) for i in range(X_train[cols].shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return vif","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.147281Z","iopub.execute_input":"2023-08-04T11:38:42.147643Z","iopub.status.idle":"2023-08-04T11:38:42.154997Z","shell.execute_reply.started":"2023-08-04T11:38:42.147613Z","shell.execute_reply":"2023-08-04T11:38:42.153719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_vif(important_df['Features'])","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.156988Z","iopub.execute_input":"2023-08-04T11:38:42.157424Z","iopub.status.idle":"2023-08-04T11:38:42.200122Z","shell.execute_reply.started":"2023-08-04T11:38:42.157392Z","shell.execute_reply":"2023-08-04T11:38:42.199016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All VIF values of important features are smaller than 5, which means multicolinearity is well addressed","metadata":{}},{"cell_type":"markdown","source":"### Visualization of factors with most significant impact on house price predication throughout the analysis","metadata":{}},{"cell_type":"code","source":"#visualizing coefficients of most important features\nimportant_df_sorted = important_df.sort_values(by='Coefficients')\n\nplt.figure(figsize=[16, 8])\nsns.barplot(x='Features', y='Coefficients', data = important_df_sorted, palette='RdYlGn')\nplt.ylabel('Coefficient', fontsize=14)\nplt.xlabel('')\nplt.xticks(fontsize=12, rotation=90)\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-04T11:38:42.201721Z","iopub.execute_input":"2023-08-04T11:38:42.202573Z","iopub.status.idle":"2023-08-04T11:38:42.595202Z","shell.execute_reply.started":"2023-08-04T11:38:42.202541Z","shell.execute_reply":"2023-08-04T11:38:42.594009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\nI made an assumption that the missing value of 'Electrical' is a record mistake and impute it with mode. \n\nIn our analysis, we used Ridge, Lasso, and ElasticNet as our predictive models. The 3 models have similar performance in terms of Test R2 Score(around 0.9), MAE (around 0.08), RMSE (around 0.11). Noticably, Ridge has the best performance -- it has the highest Test R2 score (0.9092), meaning that it has the best fitting effectiveness; it has the lowest MAE (0.0809), meaning that it generates the least errors on average; it also has the lowest RMSE (0.1148), meaning that it is least susceptible to noises and outliers. \n\nModel performance can be varied by adjusting following parameters:\n1. Threshold values for removing outliers\n2. Threshold value for removing low variance features(<0.001)\n3. Threshold value for removing features with multicolinearity(>0.8)\n4. Threshold value for RFE(n_features_to_select = 100)\n5. Therehold value for hyperparameter optimization using GridSearchCV(folds = 5)","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"# 6.Prediction on Test","metadata":{}},{"cell_type":"code","source":"# Load the data\ntest = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\ndf = test.copy()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.597146Z","iopub.execute_input":"2023-08-04T11:38:42.597604Z","iopub.status.idle":"2023-08-04T11:38:42.631730Z","shell.execute_reply.started":"2023-08-04T11:38:42.597562Z","shell.execute_reply":"2023-08-04T11:38:42.630724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess Test Data","metadata":{}},{"cell_type":"markdown","source":"The process should be set in accordance to how we preprocess train.csv except for process that reduce samples, so we will not deal with outliers. Also, no need to drop any cols since it is taken care of by rfe and lasso. Therefore, the process we pick are: 4.2.Convert Data Type, 4.4.2.Treating Missing Values for Each Feature, 4.6.1.Ordinal Mapping, 4.6.2.Binary Mapping, and 4.9.One-Hot Encoding ","metadata":{}},{"cell_type":"markdown","source":"### Convert Data Type and Deal with Missing Values","metadata":{}},{"cell_type":"code","source":"# 4.2.Convert Data Type\n##############################################################################\n# convert to object\ndf['MSSubClass'] = df['MSSubClass'].astype('object')\n\n# 4.4.2.Treating Missing Values for Each Feature\n############################################################################## \n#Impute with median\ndf['LotFrontage'].fillna(df['LotFrontage'].median(), inplace = True)\n\n#impute with 'None'\ndf['Alley'].fillna('None', inplace = True)\n\n# When missing values appears simultaneously, impute 'MasVnrType' with 'NA' and 'MasVnrArea' with 0.\ndf.loc[df['MasVnrType'].isnull() & df['MasVnrArea'].isnull(), ['MasVnrType','MasVnrArea']] = ['None',0.0]\n\n# impute with 'None' for features not missing at random (TotalBsmtSF = 0)\ncols = ['BsmtQual','BsmtCond','BsmtFinType1', 'BsmtExposure', 'BsmtFinType2']\ndf.loc[df['TotalBsmtSF'] == 0, cols] = df.loc[df['TotalBsmtSF'] == 0, cols].fillna('None')\n#impute remaining missing values with mode\ndf['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0], inplace = True)\ndf['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0], inplace = True)\n\n#Impute with mode\ndf['Electrical'].fillna(df['Electrical'].mode()[0], inplace = True)\n\n#impute with 'None'\ndf['FireplaceQu'].fillna('None', inplace = True)\n\n# impute with 'None' for features not missing at random (GarageArea = 0)\ncols = ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'GarageYrBlt']\ndf.loc[df['GarageArea'] == 0, cols] = df.loc[df['GarageArea'] == 0, cols].fillna('None')\n\n#Feature Creation \ndf['GarageYrBlt'] = df['GarageYrBlt'].apply(lambda x: 'None' if x == 'None' else ('New' if x > 1980 else 'Old'))\n\n#impute with 'None'\ndf['PoolQC'].fillna('None', inplace = True)\n\n#impute with 'None'\ndf['Fence'].fillna('None', inplace = True)\n\n#impute with 'None'\ndf['MiscFeature'].fillna('None', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.633619Z","iopub.execute_input":"2023-08-04T11:38:42.634075Z","iopub.status.idle":"2023-08-04T11:38:42.675814Z","shell.execute_reply.started":"2023-08-04T11:38:42.634034Z","shell.execute_reply":"2023-08-04T11:38:42.674611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing values\ntotal = df.isnull().sum().sort_values(ascending=False)\ntotal = total[total > 0] \npercent = (df.isnull().sum() / df.shape[0] * 100).round(2).sort_values(ascending=False)\npercent = percent[percent > 0]  \n\ndtypes = df.dtypes[total.index]\nresult = pd.concat([total, percent, dtypes], axis=1, keys=['Total', 'Percent', 'Dtype'])\nresult","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-04T11:38:42.677256Z","iopub.execute_input":"2023-08-04T11:38:42.677609Z","iopub.status.idle":"2023-08-04T11:38:42.746460Z","shell.execute_reply.started":"2023-08-04T11:38:42.677579Z","shell.execute_reply":"2023-08-04T11:38:42.745248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting list for remaining missing values\ncolumns_with_missing_values = df.columns[df.isnull().any()].tolist()\nprint(columns_with_missing_values)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.747794Z","iopub.execute_input":"2023-08-04T11:38:42.748148Z","iopub.status.idle":"2023-08-04T11:38:42.780068Z","shell.execute_reply.started":"2023-08-04T11:38:42.748119Z","shell.execute_reply":"2023-08-04T11:38:42.778780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find all continous columns\ncontin_columns = [cols for cols in columns_with_missing_values if cols in continous_features]\ncontin_columns","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.781454Z","iopub.execute_input":"2023-08-04T11:38:42.781862Z","iopub.status.idle":"2023-08-04T11:38:42.790054Z","shell.execute_reply.started":"2023-08-04T11:38:42.781827Z","shell.execute_reply":"2023-08-04T11:38:42.788846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill continous features with median\ndf[contin_columns] = df[contin_columns].fillna(df[contin_columns].median())","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.791536Z","iopub.execute_input":"2023-08-04T11:38:42.791972Z","iopub.status.idle":"2023-08-04T11:38:42.811378Z","shell.execute_reply.started":"2023-08-04T11:38:42.791938Z","shell.execute_reply":"2023-08-04T11:38:42.809924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill categorical features with mode\ncate_columns = [cols for cols in columns_with_missing_values if cols not in contin_columns]\ndf[cate_columns] = df[cate_columns].fillna(df[cate_columns].mode().iloc[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.813052Z","iopub.execute_input":"2023-08-04T11:38:42.813444Z","iopub.status.idle":"2023-08-04T11:38:42.858248Z","shell.execute_reply.started":"2023-08-04T11:38:42.813411Z","shell.execute_reply":"2023-08-04T11:38:42.857066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().any().any()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.859559Z","iopub.execute_input":"2023-08-04T11:38:42.859934Z","iopub.status.idle":"2023-08-04T11:38:42.869021Z","shell.execute_reply.started":"2023-08-04T11:38:42.859902Z","shell.execute_reply":"2023-08-04T11:38:42.867814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Encoding","metadata":{}},{"cell_type":"code","source":"# 4.6.1.Ordinal Mapping\n############################################################################## \nordinal_features_1 = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', \n                      'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n\n# conduct ordinal encoding for these features\nfor i in ordinal_features_1:\n    df[i] = df[i].map({'Ex':9, 'Gd':7, 'TA':5, 'Fa':3, 'Po':2, 'None':0 })\n\n# 4.6.2.Binary Mapping\n############################################################################## \n# Applying the binary mapping to binary columns\ndf['Street'] = df['Street'].map({'Pave': 1, \"Grvl\": 0})\ndf['Utilities'] = df['Utilities'].map({'AllPub': 1, \"NoSeWa\": 0})\ndf['CentralAir'] = df['CentralAir'].map({'Y': 1, \"N\": 0})\n\n# 4.9.One-Hot Encoding\n############################################################################## \n#find nominal features\nnomin_features = df.select_dtypes(exclude = np.number).columns\n\n#perform one-hot encoding to nominal features\ndf_dummy = pd.get_dummies(df[nomin_features], drop_first = True)\n\n#concat dummy features to data\ndf = pd.concat([df, df_dummy], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.870859Z","iopub.execute_input":"2023-08-04T11:38:42.871225Z","iopub.status.idle":"2023-08-04T11:38:42.939250Z","shell.execute_reply.started":"2023-08-04T11:38:42.871194Z","shell.execute_reply":"2023-08-04T11:38:42.938291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Scaling","metadata":{}},{"cell_type":"code","source":"# Remembers that features_to_scal are features selected by RFE\ndf[features_to_scal] = scaler.transform(df[features_to_scal])","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:42.940602Z","iopub.execute_input":"2023-08-04T11:38:42.940973Z","iopub.status.idle":"2023-08-04T11:38:42.958894Z","shell.execute_reply.started":"2023-08-04T11:38:42.940944Z","shell.execute_reply":"2023-08-04T11:38:42.957728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Coefficients Extraction","metadata":{}},{"cell_type":"code","source":"ridge_df = pd.DataFrame({'Features': ridge.feature_names_in_, 'Coefficients': ridge.coef_})\nridge_df = ridge_df.sort_values('Coefficients', ascending = False).reset_index().drop('index', axis = 1)\nridge_df","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-04T11:38:42.960426Z","iopub.execute_input":"2023-08-04T11:38:42.960843Z","iopub.status.idle":"2023-08-04T11:38:42.985757Z","shell.execute_reply.started":"2023-08-04T11:38:42.960806Z","shell.execute_reply":"2023-08-04T11:38:42.984487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract features\nfeatures = ridge_df['Features']\n\n# Convert 'features' into a set\nfeatures_set = set(features)\n\n# Convert the feature names in 'df' into another set\ndf_features_set = set(df.columns)\n\n# Find the features in 'features' that are not present in 'df'\nfeatures_not_in_df = list(features_set - df_features_set)\n\n# Print the result\nprint(\"Features in 'features' but not in 'df':\")\nprint(features_not_in_df)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-04T11:38:42.987965Z","iopub.execute_input":"2023-08-04T11:38:42.988792Z","iopub.status.idle":"2023-08-04T11:38:43.000093Z","shell.execute_reply.started":"2023-08-04T11:38:42.988742Z","shell.execute_reply":"2023-08-04T11:38:42.998624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_rows = ridge_df.loc[ridge_df['Features'].isin(features_not_in_df)]\nfiltered_rows","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:43.002176Z","iopub.execute_input":"2023-08-04T11:38:43.002710Z","iopub.status.idle":"2023-08-04T11:38:43.019132Z","shell.execute_reply.started":"2023-08-04T11:38:43.002645Z","shell.execute_reply":"2023-08-04T11:38:43.017890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ridge_df = ridge_df[~ridge_df['Features'].isin(features_not_in_df)]\nridge_df = ridge_df.reset_index().drop('index', axis = 1)\nridge_df","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-04T11:38:43.020970Z","iopub.execute_input":"2023-08-04T11:38:43.021638Z","iopub.status.idle":"2023-08-04T11:38:43.048565Z","shell.execute_reply.started":"2023-08-04T11:38:43.021567Z","shell.execute_reply":"2023-08-04T11:38:43.047465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 1: Extracting feature names and corresponding linear regression coefficients from lasso_df\nfeatures = ridge_df['Features']\ncoefficients = ridge_df['Coefficients']\nintercept = ridge.intercept_\n\n# Step 2: Selecting corresponding features from df, note that index will be inherited to df_features\ndf_features = df[features]\n\n# Step 3: Predicting 'SalePrice' using linear regression coefficients\n# The prediction is the dot product of the coefficients and the selected features\npredicted_SalePrice = df_features.dot(coefficients.values)+intercept\n\ndf_features.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:43.050140Z","iopub.execute_input":"2023-08-04T11:38:43.050587Z","iopub.status.idle":"2023-08-04T11:38:43.169785Z","shell.execute_reply.started":"2023-08-04T11:38:43.050543Z","shell.execute_reply":"2023-08-04T11:38:43.168237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 4: Adding the predicted 'SalePrice' to df\ndf['SalePrice'] = predicted_SalePrice\n\n# Show the first few rows of the updated DataFrame\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:43.172387Z","iopub.execute_input":"2023-08-04T11:38:43.173439Z","iopub.status.idle":"2023-08-04T11:38:43.322349Z","shell.execute_reply.started":"2023-08-04T11:38:43.173367Z","shell.execute_reply":"2023-08-04T11:38:43.320887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final Prediction of SalePrice on Test.CSV","metadata":{}},{"cell_type":"code","source":"#Reverse logarithmic transformation for target\ndf_result = df[['Id', 'SalePrice']]\ndf_result['SalePrice'] = np.exp(df_result['SalePrice'])\ndf_result.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:43.323895Z","iopub.execute_input":"2023-08-04T11:38:43.324255Z","iopub.status.idle":"2023-08-04T11:38:43.338876Z","shell.execute_reply.started":"2023-08-04T11:38:43.324221Z","shell.execute_reply":"2023-08-04T11:38:43.337520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Export Results to CSV","metadata":{}},{"cell_type":"code","source":"df_result.to_csv('yuanshan_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:43.342745Z","iopub.execute_input":"2023-08-04T11:38:43.343449Z","iopub.status.idle":"2023-08-04T11:38:43.356504Z","shell.execute_reply.started":"2023-08-04T11:38:43.343412Z","shell.execute_reply":"2023-08-04T11:38:43.355173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_result.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-04T11:38:43.358122Z","iopub.execute_input":"2023-08-04T11:38:43.358552Z","iopub.status.idle":"2023-08-04T11:38:43.365823Z","shell.execute_reply.started":"2023-08-04T11:38:43.358519Z","shell.execute_reply":"2023-08-04T11:38:43.364603Z"},"trusted":true},"execution_count":null,"outputs":[]}]}